# Base config for remote-vllm distribution (embedded in operator binary)
# User CR specs merge over this config.
# inference points to remote vLLM; users typically override config.url.
version: 2
apis:
  - inference
  - safety
  - agents
  - memory
  - telemetry
  - tool_runtime
  - datasetio
  - eval
  - scoring
  - inspect

providers:
  inference:
    - provider_id: vllm
      provider_type: remote::vllm
      config:
        url: http://localhost:8000
  safety:
    - provider_id: meta-reference
      provider_type: inline::meta-reference
      config: {}
  vector_io:
    - provider_id: faiss
      provider_type: inline::faiss
      config: {}
  tool_runtime:
    - provider_id: rag-runtime
      provider_type: inline::rag-runtime
      config: {}
  telemetry:
    - provider_id: console
      provider_type: inline::console
      config: {}

metadata_store:
  type: sqlite
  db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/remote-vllm}/metadata.db

inference_store:
  type: sqlite
  db_path: ${env.SQLITE_STORE_DIR:=~/.llama/distributions/remote-vllm}/inference.db
